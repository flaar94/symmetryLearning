{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import islice, cycle\n",
    "from torch.utils.data.dataset import random_split\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from windows_inhibitor import WindowsInhibitor\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from numpy.random import default_rng\n",
    "import os.path as path\n",
    "rng = default_rng()\n",
    "device = torch.device(\"cuda:0\" if True else \"cpu\")\n",
    "DATA_PATH = 'strict_dataset.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "class TrainSet(torch.utils.data.Dataset):\n",
    "    def __init__(self, path, transform=None):\n",
    "        super().__init__()\n",
    "        self.path = path\n",
    "        self.data = np.load(path)\n",
    "        self.rows = self.data.shape[0]\n",
    "        self.cols = self.data.shape[1]\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.rows\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = torch.tensor(self.data[idx], dtype=torch.float)\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "class LinearTransformEM(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=0):\n",
    "        pass\n",
    "\n",
    "    def transform(self, X):\n",
    "        pass\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# ae.eval()\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5), (0.5))])\n",
    "\n",
    "classes = list(range(10))\n",
    "trainset = TrainSet(DATA_PATH)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "neighbor_data = np.array([list(x.view(-1).numpy()) for x in trainset])\n",
    "neighbors = NearestNeighbors(n_neighbors=5, n_jobs=6)\n",
    "\n",
    "neighbors.fit(neighbor_data)\n",
    "\n",
    "def get_neighbors(data, neighbors, data_points, k=0):\n",
    "    with torch.no_grad():\n",
    "        nb_indices = neighbors.kneighbors(data_points.cpu())[1]\n",
    "        nb_indices = nb_indices[:, k]\n",
    "        out_tensor = torch.tensor(data[nb_indices], dtype=torch.float)\n",
    "        out_tensor.requires_grad = False\n",
    "    return out_tensor\n",
    "\n",
    "def get_neighbor_indices(data, neighbors, data_points, k=0):\n",
    "    with torch.no_grad():\n",
    "        nb_indices = neighbors.kneighbors(data_points.cpu())[1]\n",
    "        nb_indices = nb_indices[:, k]\n",
    "        # out_tensor = torch.tensor(data[nb_indices], dtype=torch.float)\n",
    "        # out_tensor.requires_grad = False\n",
    "    return nb_indices"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(trainset.cols, trainset.cols, bias=False)\n",
    "        # self.trans = torch.diag(torch.tensor([-1 if k < 28*28/2 else 1 for k in range(28*28)], dtype=torch.float))\n",
    "        # self.trans = torch.diag(torch.tensor([-1 if i < 28 * 28 / 2 else 1 for i in range(28 * 28)],\n",
    "        #                                      dtype=torch.float, requires_grad=False))\n",
    "        self.trans = torch.block_diag(*[torch.tensor([[0, 1], [1, 0]], dtype=torch.float) for _ in range(trainset.cols // 2)])\n",
    "        # torch.nn.init.uniform_(self.fc1.weight, -10 ** -4, 10 ** -4)\n",
    "        # self.fc1.weight += torch.eye(28, 28).view(-1)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x = x.view(-1, 28 * 28)\n",
    "        x = self.fc1(x)\n",
    "        # y = x\n",
    "\n",
    "        x = F.linear(x, self.trans)\n",
    "\n",
    "        # y = F.linear(y, self.fc1.weight.t())\n",
    "        x = F.linear(x, self.fc1.weight.t())\n",
    "\n",
    "        # y = y.view(-1, 1, 28, 28)\n",
    "        # x = x.view(-1, 1, 28, 28)\n",
    "        return x #, y\n",
    "\n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        # torch.nn.init.uniform_(m.weight, -10 ** -4, 10 ** -4)\n",
    "        torch.nn.init.orthogonal_(m.weight)\n",
    "        # with torch.no_grad():\n",
    "        #     m.weight += torch.eye(28 * 28)\n",
    "\n",
    "\n",
    "net = Net()\n",
    "net.apply(init_weights)\n",
    "total_time = 0\n",
    "true_epoch = 0\n",
    "train_error_list = []\n",
    "test_error_list = []\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# state_dict = torch.load('symmetry_net.pkl')\n",
    "# net.load_state_dict(state_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=20,\n",
    "                                          shuffle=True, pin_memory=True)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.003, momentum=0.5, weight_decay=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preventing Windows from going to sleep\n",
      "[1, 100] loss: 1.6717, ortho_loss: 0.0924, ground_truth_loss: 0.0634, \n",
      "Allowing Windows to go to sleep\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-9-2ac4aaf93e9f>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     22\u001B[0m             \u001B[0moutputs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnet\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     23\u001B[0m             \u001B[0mk\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mrng\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mchoice\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mrange\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m5\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 24\u001B[1;33m             \u001B[0mnbs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mget_neighbors\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mneighbor_data\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mneighbors\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0moutputs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdetach\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mk\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mk\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     25\u001B[0m             \u001B[1;31m# print(type(outputs), type(nbs))\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     26\u001B[0m             \u001B[0mloss\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcriterion\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0moutputs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnbs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-5-51c16610443c>\u001B[0m in \u001B[0;36mget_neighbors\u001B[1;34m(data, neighbors, data_points, k)\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[1;32mdef\u001B[0m \u001B[0mget_neighbors\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mneighbors\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdata_points\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mk\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      7\u001B[0m     \u001B[1;32mwith\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mno_grad\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 8\u001B[1;33m         \u001B[0mnb_indices\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mneighbors\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mkneighbors\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata_points\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcpu\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      9\u001B[0m         \u001B[0mnb_indices\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnb_indices\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mk\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     10\u001B[0m         \u001B[0mout_tensor\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtensor\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mnb_indices\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfloat\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\envs\\Conda_test\\lib\\site-packages\\sklearn\\neighbors\\_base.py\u001B[0m in \u001B[0;36mkneighbors\u001B[1;34m(self, X, n_neighbors, return_distance)\u001B[0m\n\u001B[0;32m    663\u001B[0m                 delayed_query(\n\u001B[0;32m    664\u001B[0m                     self._tree, X[s], n_neighbors, return_distance)\n\u001B[1;32m--> 665\u001B[1;33m                 \u001B[1;32mfor\u001B[0m \u001B[0ms\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mgen_even_slices\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mn_jobs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    666\u001B[0m             )\n\u001B[0;32m    667\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\envs\\Conda_test\\lib\\site-packages\\joblib\\parallel.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m   1069\u001B[0m                 \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_backend\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstop_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1070\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_managed_backend\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1071\u001B[1;33m                 \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_terminate_backend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1072\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_jobs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mlist\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1073\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_pickle_cache\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\envs\\Conda_test\\lib\\site-packages\\joblib\\parallel.py\u001B[0m in \u001B[0;36m_terminate_backend\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    762\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m_terminate_backend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    763\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_backend\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 764\u001B[1;33m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_backend\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mterminate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    765\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    766\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m_dispatch\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbatch\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\envs\\Conda_test\\lib\\site-packages\\joblib\\_parallel_backends.py\u001B[0m in \u001B[0;36mterminate\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    241\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_pool\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    242\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_pool\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mclose\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 243\u001B[1;33m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_pool\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mterminate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# terminate does a join()\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    244\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_pool\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    245\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\envs\\Conda_test\\lib\\multiprocessing\\pool.py\u001B[0m in \u001B[0;36mterminate\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    546\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_state\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mTERMINATE\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    547\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_worker_handler\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_state\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mTERMINATE\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 548\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_terminate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    549\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    550\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mjoin\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\envs\\Conda_test\\lib\\multiprocessing\\util.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, wr, _finalizer_registry, sub_debug, getpid)\u001B[0m\n\u001B[0;32m    222\u001B[0m                 sub_debug('finalizer calling %s with args %s and kwargs %s',\n\u001B[0;32m    223\u001B[0m                           self._callback, self._args, self._kwargs)\n\u001B[1;32m--> 224\u001B[1;33m                 \u001B[0mres\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_callback\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_args\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_kwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    225\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_weakref\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_callback\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_args\u001B[0m \u001B[1;33m=\u001B[0m\u001B[0;31m \u001B[0m\u001B[0;31m\\\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    226\u001B[0m                             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_kwargs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_key\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\envs\\Conda_test\\lib\\multiprocessing\\pool.py\u001B[0m in \u001B[0;36m_terminate_pool\u001B[1;34m(cls, taskqueue, inqueue, outqueue, pool, worker_handler, task_handler, result_handler, cache)\u001B[0m\n\u001B[0;32m    592\u001B[0m         \u001B[0mutil\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdebug\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'joining worker handler'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    593\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mthreading\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcurrent_thread\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mworker_handler\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 594\u001B[1;33m             \u001B[0mworker_handler\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mjoin\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    595\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    596\u001B[0m         \u001B[1;31m# Terminate workers which haven't already finished.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\envs\\Conda_test\\lib\\threading.py\u001B[0m in \u001B[0;36mjoin\u001B[1;34m(self, timeout)\u001B[0m\n\u001B[0;32m   1042\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1043\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mtimeout\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1044\u001B[1;33m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_wait_for_tstate_lock\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1045\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1046\u001B[0m             \u001B[1;31m# the behavior of a negative timeout isn't documented, but\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\envs\\Conda_test\\lib\\threading.py\u001B[0m in \u001B[0;36m_wait_for_tstate_lock\u001B[1;34m(self, block, timeout)\u001B[0m\n\u001B[0;32m   1058\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mlock\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m  \u001B[1;31m# already determined that the C code is done\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1059\u001B[0m             \u001B[1;32massert\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_is_stopped\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1060\u001B[1;33m         \u001B[1;32melif\u001B[0m \u001B[0mlock\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0macquire\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mblock\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtimeout\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1061\u001B[0m             \u001B[0mlock\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrelease\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1062\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_stop\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "with WindowsInhibitor():\n",
    "    net.to(device)\n",
    "    net.trans = net.trans.to(device)\n",
    "    id_mat = torch.eye(trainset.cols, requires_grad=False, device=device)\n",
    "    for epoch in range(100):  # loop over the dataset multiple times\n",
    "        start_time = time.time()\n",
    "        true_epoch += 1\n",
    "        running_loss = 0.0\n",
    "        epoch_loss = 0.0\n",
    "        running_ortho_loss = 0.0\n",
    "        running_discont_loss = 0.0\n",
    "        running_ground_truth_loss = 0.0\n",
    "        true_train_total = 0.0\n",
    "        total_train = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # get the inputs\n",
    "            inputs = data\n",
    "            inputs = inputs.to(device)\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            k = rng.choice(range(5))\n",
    "            nbs = get_neighbors(neighbor_data, neighbors, outputs.detach(), k=k).to(device)\n",
    "            # print(type(outputs), type(nbs))\n",
    "            loss = criterion(outputs, nbs)\n",
    "            running_loss += loss.detach()\n",
    "            epoch_loss += loss.detach()\n",
    "\n",
    "            orth_loss = criterion(net.fc1.weight.t() @ net.fc1.weight, id_mat) * 3_000\n",
    "            running_ortho_loss += orth_loss.detach()\n",
    "\n",
    "            loss += orth_loss\n",
    "\n",
    "            with torch.no_grad():\n",
    "                ground_truth_loss = criterion(net.fc1.weight.t() @ net.trans @ net.fc1.weight, net.trans)\n",
    "                running_ground_truth_loss += ground_truth_loss.detach()\n",
    "                mat = net.fc1.weight.t() @ net.trans @ net.fc1.weight\n",
    "\n",
    "            # print(loss.detach(), orth_loss.detach())\n",
    "            total_train += 1\n",
    "            true_train_total += 1\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # with torch.no_grad():\n",
    "            #     print(net.fc1.weight.det())\n",
    "                # net.fc1.weight /= torch.abs(net.fc1.weight.det()) ** (1 / (28 * 28))\n",
    "            optimizer.zero_grad()\n",
    "            # print(f'loss: {running_loss / total_train:.4f}')\n",
    "            # print statistics\n",
    "            if i % 100 == 99:    # print every 25 mini-batches\n",
    "                print(f'[{true_epoch}, {i + 1}] '\n",
    "                      f'loss: {running_loss / total_train:.4f}, '\n",
    "                      f'ortho_loss: {running_ortho_loss / total_train:.4f}, '\n",
    "                      f'ground_truth_loss: {running_ground_truth_loss / total_train:.4f}, ')\n",
    "                running_loss = 0.0\n",
    "                running_ortho_loss = 0.0\n",
    "                running_discont_loss = 0.0\n",
    "                running_ground_truth_loss = 0.0\n",
    "                total_train = 0.0\n",
    "        print(f'total error = {epoch_loss / true_train_total:.4f}')\n",
    "        with torch.no_grad():\n",
    "            print(get_neighbor_indices(neighbor_data, neighbors, net(trainset[:10].to(device)), k=0))\n",
    "        # test_error = 0.0\n",
    "        # total = 0\n",
    "        # with torch.no_grad():\n",
    "        #     for data in testloader:\n",
    "        #         images, labels = data\n",
    "        #         images, labels = images.to(device), labels.to(device)\n",
    "        #         outputs = net(images)\n",
    "        #         test_loss = criterion(outputs, images)\n",
    "        #         total += labels.size(0)\n",
    "        #         test_error += test_loss.detach()\n",
    "        #     test_error_list.append(test_error / total)\n",
    "\n",
    "        total_time += time.time() - start_time\n",
    "        # print(f'Accuracy of the network on the 10000 test images: {100 * test_error / total}')\n",
    "        print(f'Finished epoch, cumulative time: {total_time}s')\n",
    "    print(\"Finished training!\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mat = net.fc1.weight.t() @ net.trans @ net.fc1.weight\n",
    "(mat * (torch.abs((mat)) > 0.001).float())[4:10, 4:10]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "(net.fc1.weight.t() @ net.fc1.weight).det()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trainset[:3]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trainset[500:503]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "net.to(device)\n",
    "net.trans = net.trans.to(device)\n",
    "with torch.no_grad():\n",
    "    print(get_neighbor_indices(neighbor_data, neighbors, net(trainset[600:625].to(device)), k=0))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    print(get_neighbor_indices(neighbor_data, neighbors, net(trainset[400:425].to(device)), k=1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}